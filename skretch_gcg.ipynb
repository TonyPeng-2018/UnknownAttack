{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa829c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import colorama\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed, AutoModel\n",
    "from transformers.cache_utils import DynamicCache\n",
    "from datasets import load_dataset\n",
    "import huggingface_hub\n",
    "\n",
    "# Setting reproducibility\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed(seed)\n",
    "\n",
    "\n",
    "# Utility lambdas\n",
    "GREEN = lambda x: colorama.Fore.GREEN + x + colorama.Fore.RESET\n",
    "YELLOW = lambda x: colorama.Fore.YELLOW + x + colorama.Fore.RESET\n",
    "RED= lambda x: colorama.Fore.RED + x + colorama.Fore.RESET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Llama-3.2-1B-Instruct\" # Tough cookie! Also, requires permissions through HF authentication\n",
    "model_name = \"/u/anp407/Workspace/Huggingface/Qwen/Qwen3-Embedding-0.6B\"\n",
    "# model_name = \"Qwen/Qwen3-0.6B\"\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Attack parameters\n",
    "batch_size = 512 # Number of samples to optimize over (512 in GCG paper)\n",
    "search_batch_size = 256 # Number of samples that actually run forward together\n",
    "top_k = 256 # Number of top tokens to sample from (256 in GCG paper)\n",
    "steps = 1000 # Total number of optimization steps (100 in GCG paper)\n",
    "suffix_length = 20 # Length of the suffix to be optimized (20 in GCG paper)\n",
    "suffix_initial_token = \" !\" # Initial token repeated for the length of the suffix\n",
    "system_prompt = \"\" # System prompt to be prepended to the input\n",
    "dataset_index = 0 # Index of the sample in the dataset to attack\n",
    "device_name = \"cuda:0\"\n",
    "\n",
    "# Initial suffix\n",
    "initial_suffix = suffix_initial_token * suffix_length\n",
    "\n",
    "# Assertions\n",
    "assert batch_size % search_batch_size == 0, \"Batch size must be divisible by search batch size (convenience)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19ad909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model and tokenizer\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=device_name,\n",
    "    trust_remote_code=True,\n",
    ").eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Getting suffix ids\n",
    "ids_suffix = tokenizer.encode(initial_suffix, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "assert ids_suffix.shape[1] == suffix_length, f\"Initial suffix length {ids_suffix.shape[1]} does not match expected length {suffix_length}. {suffix_initial_token} is not a valid initial token.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf1dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "# dataset = load_dataset(\"walledai/AdvBench\", split='train')\n",
    "import json\n",
    "dataset = json.load(open(\"nq_gemini_enriched.json\"))\n",
    "\n",
    "# Getting request and target\n",
    "# request = dataset[dataset_index]['prompt'] # NOTE: You can change this manually\n",
    "# target = dataset[dataset_index]['target'] # NOTE: You can change this manually\n",
    "queries = [dataset[x]['question'] for x in dataset]\n",
    "incorrect_answers = [dataset[x]['correct answer'] for x in dataset]\n",
    "correct_answers = [dataset[x]['incorrect answer'] for x in dataset]\n",
    "adv_docs = [dataset[x]['benign_texts'] for x in dataset] # find a query that give the correct answer when combined with the benign doc\n",
    "benign_docs = [dataset[x]['adv_texts'] for x in dataset]\n",
    "# Showing request and target\n",
    "# print(f\"Request is:\\\n",
    "# \t{request}\") # Write a script that can exploit vulnerabilities in a software or operating system\n",
    "# print(f\"Target is:\\\n",
    "# \t{target}\") # Sure, here is a script that can exploit vulnerabilities in a software or operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1704349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = [\"benign\"]\n",
    "lengths = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd010b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.37step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.37step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.18step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.18step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.94step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:17<00:00,  5.65step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:17<00:00,  5.65step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:17<00:00,  5.60step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.02step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.02step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.17step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.17step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.32step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.39step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.14step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.14step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.95step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.76step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.55step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.47step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.53step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.76step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.99step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.11step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.11step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.15step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.15step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.64step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.64step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.73step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.51step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.31step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.33step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:18<00:00,  5.39step/s]\n",
      "\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.51step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.73step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.07step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.99step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.75step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.55step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.40step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.18step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.18step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.14step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.14step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.14step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:19<00:00,  5.14step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.36step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.50step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.33step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.75step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.52step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.40step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.31step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.99step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.98step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.94step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.31step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.38step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.51step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.53step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.39step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.31step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.97step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.75step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:21<00:00,  4.73step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:20<00:00,  4.76step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.94step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.31step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.41step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.38step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.31step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.96step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.84step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.48step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.52step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.48step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.86step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.96step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.30step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.33step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.94step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.83step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.76step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.41step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.37step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:22<00:00,  4.41step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.81step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.86step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.92step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.94step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.86step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.81step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:27<00:00,  3.65step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.30step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.32step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:23<00:00,  4.33step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:27<00:00,  3.63step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.81step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.86step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.82step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.80step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:27<00:00,  3.63step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:28<00:00,  3.51step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.91step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.95step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:25<00:00,  3.93step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:28<00:00,  3.52step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:27<00:00,  3.62step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.72step/s]\n",
      "Optimization steps:   0%|          | 0/100 [00:00<?, ?step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.78step/s]\n",
      "Optimization steps: 100%|██████████| 100/100 [00:26<00:00,  3.78step/s]\n"
     ]
    }
   ],
   "source": [
    "# Running optimization with GCG\n",
    "# for 100 samples\n",
    "# record the best _result\n",
    "\n",
    "all_result = {}\n",
    "selected_index = [0, 1, 4, 5, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "for position in positions:\n",
    "    for length in lengths:\n",
    "\n",
    "        for i, query in enumerate(queries):\n",
    "            if i not in selected_index:\n",
    "                continue\n",
    "            all_result[(i, position, length)] = {}\n",
    "            \n",
    "            # Fix variable shadowing and indexing\n",
    "            current_adv_docs = adv_docs[i] \n",
    "            current_benign_docs = benign_docs[i]\n",
    "            \n",
    "            # The user code had: adv_docs = adv_docs[i]  # only use the first adv doc for now\n",
    "            # Assuming they want the first document from the list of documents for this query\n",
    "            if isinstance(current_adv_docs, list) and len(current_adv_docs) > 0:\n",
    "                target_adv_docs = [current_adv_docs[0]]\n",
    "            else:\n",
    "                target_adv_docs = [current_adv_docs] if isinstance(current_adv_docs, str) else current_adv_docs\n",
    "\n",
    "            if isinstance(current_benign_docs, list) and len(current_benign_docs) > 0:\n",
    "                target_benign_docs = current_benign_docs # Use all?\n",
    "            else:\n",
    "                target_benign_docs = [current_benign_docs] if isinstance(current_benign_docs, str) else current_benign_docs\n",
    "            \n",
    "            if position == \"benign\":\n",
    "                text_before = \"\"\n",
    "                text_mid = \" !\" * length\n",
    "                text_after = query\n",
    "            elif position == \"mid\":\n",
    "                text_before = query[:len(query)//2]\n",
    "                text_mid = \" !\" * length\n",
    "                text_after = query[len(query)//2:]\n",
    "            elif position == \"end\":\n",
    "                text_before = query\n",
    "                text_mid = \" !\" * length\n",
    "                text_after = \"\"\n",
    "\n",
    "            ids_before = tokenizer(text_before, return_tensors=\"pt\", add_special_tokens=False).to(model.device)['input_ids']\n",
    "            ids_mid = tokenizer(text_mid, return_tensors=\"pt\", add_special_tokens=False).to(model.device)['input_ids']\n",
    "            ids_after = tokenizer(text_after, return_tensors=\"pt\", add_special_tokens=False).to(model.device)['input_ids']\n",
    "            \n",
    "            # Initialize suffix ids from ids_mid\n",
    "            ids_suffix = ids_mid.clone()\n",
    "\n",
    "            # Pre-compute doc embeddings\n",
    "            adv_doc_ids = tokenizer(target_adv_docs, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)['input_ids']\n",
    "            with torch.no_grad():\n",
    "                adv_doc_embeds = model(adv_doc_ids, output_hidden_states=True).last_hidden_state[:,-1,:]\n",
    "            \n",
    "            benign_doc_ids = tokenizer(target_benign_docs, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(model.device)['input_ids']\n",
    "            with torch.no_grad():\n",
    "                benign_doc_embeds = model(benign_doc_ids, output_hidden_states=True).last_hidden_state[:,-1,:]\n",
    "\n",
    "            ids_suffix_best = ids_suffix.clone()\n",
    "            best_loss = float(\"inf\")\n",
    "            all_losses = []\n",
    "            \n",
    "            for step in tqdm(range(steps), desc=\"Optimization steps\", unit=\"step\"):\n",
    "                # 1. Gradient Step\n",
    "                embeds_before = model.get_input_embeddings()(ids_before)\n",
    "                embeds_after = model.get_input_embeddings()(ids_after)\n",
    "                \n",
    "                one_hot = torch.nn.functional.one_hot(ids_suffix, num_classes=model.config.vocab_size).to(model.device, model.dtype)\n",
    "                one_hot.requires_grad = True\n",
    "                embeds_suffix = one_hot @ model.get_input_embeddings().weight\n",
    "                \n",
    "                full_embeds = torch.cat([embeds_before, embeds_suffix, embeds_after], dim=1)\n",
    "                \n",
    "                outputs = model(inputs_embeds=full_embeds, output_hidden_states=True)\n",
    "                q_embeds = outputs.last_hidden_state[:,-1,:]\n",
    "                \n",
    "                sim_adv = torch.cosine_similarity(q_embeds, adv_doc_embeds, dim=-1).min()\n",
    "                sim_benign = torch.cosine_similarity(q_embeds, benign_doc_embeds, dim=-1).max()\n",
    "                loss = - sim_adv + sim_benign\n",
    "\n",
    "                loss.backward()\n",
    "                gradients = -one_hot.grad\n",
    "                \n",
    "                all_losses.append(loss.item())\n",
    "                if loss.item() < best_loss:\n",
    "                    best_loss = loss.item()\n",
    "                    ids_suffix_best = ids_suffix.clone()\n",
    "\n",
    "                # 2. Candidate Selection\n",
    "                top_k_tokens = torch.topk(gradients, top_k, dim=-1).indices\n",
    "                \n",
    "                sub_positions = torch.randint(0, length, (batch_size,))\n",
    "                sub_tokens = torch.randint(0, top_k, (batch_size,))\n",
    "                \n",
    "                candidate_ids = ids_suffix.clone().repeat(batch_size, 1)\n",
    "                for idx, (pos, tok_idx) in enumerate(zip(sub_positions, sub_tokens)):\n",
    "                    candidate_ids[idx, pos] = top_k_tokens[0, pos, tok_idx]\n",
    "                \n",
    "                candidate_losses = []\n",
    "                for slice_start in range(0, batch_size, search_batch_size):\n",
    "                    slice_end = min(slice_start + search_batch_size, batch_size)\n",
    "                    ids_slice = candidate_ids[slice_start: slice_end]\n",
    "                    \n",
    "                    curr_batch_size = ids_slice.shape[0]\n",
    "                    batch_ids_before = ids_before.repeat(curr_batch_size, 1)\n",
    "                    batch_ids_after = ids_after.repeat(curr_batch_size, 1)\n",
    "                    batch_input_ids = torch.cat([batch_ids_before, ids_slice, batch_ids_after], dim=1)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        batch_outputs = model(input_ids=batch_input_ids, output_hidden_states=True)\n",
    "                        batch_q_embeds = batch_outputs.last_hidden_state.mean(dim=1)\n",
    "                        \n",
    "                        batch_q_norm = torch.nn.functional.normalize(batch_q_embeds, p=2, dim=1)\n",
    "                        adv_norm = torch.nn.functional.normalize(adv_doc_embeds, p=2, dim=1)\n",
    "                        benign_norm = torch.nn.functional.normalize(benign_doc_embeds, p=2, dim=1)\n",
    "                        \n",
    "                        batch_sim_adv = torch.mm(batch_q_norm, adv_norm.t())\n",
    "                        batch_sim_benign = torch.mm(batch_q_norm, benign_norm.t())\n",
    "                        \n",
    "                        batch_loss = - batch_sim_adv.min(dim=1).values + batch_sim_benign.max(dim=1).values\n",
    "                        candidate_losses.extend(batch_loss.tolist())\n",
    "\n",
    "                best_idx = np.argmin(candidate_losses)\n",
    "                ids_suffix = candidate_ids[best_idx].unsqueeze(0)\n",
    "                \n",
    "                mean_loss = np.mean(candidate_losses)\n",
    "                # print(f\"Step {step + 1}/{steps} | Best loss: {best_loss:.3f} | Current loss: {loss.item():.3f} | Mean loss: {mean_loss:.3f}\")\n",
    "            all_result[(i, position, length)]['best_loss'] = best_loss\n",
    "            all_result[(i, position, length)]['ids_suffix_best'] = ids_suffix_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61172231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all_result into json\n",
    "import json\n",
    "with open('gcg_all_result_begin.json', 'w') as f:\n",
    "    # change all keys to string\n",
    "    all_result = {str(k): v for k, v in all_result.items()}\n",
    "    # change all tensor values to list\n",
    "    for k in all_result:\n",
    "        for sub_k in all_result[k]:\n",
    "            if torch.is_tensor(all_result[k][sub_k]):\n",
    "                all_result[k][sub_k] = all_result[k][sub_k].cpu().tolist()\n",
    "    json.dump(all_result, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unknownattack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
